# üöÄ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng AI v·ªõi Ollama (Mi·ªÖn Ph√≠ 100%)

## ‚úÖ ƒê√£ Chuy·ªÉn Sang Ollama

Thay v√¨ s·ª≠ d·ª•ng Google Vertex AI (t·ªën ph√≠), gi·ªù ·ª©ng d·ª•ng s·ª≠ d·ª•ng **Ollama** - AI ch·∫°y local, ho√†n to√†n mi·ªÖn ph√≠!

---

## üì¶ C√†i ƒê·∫∑t Ollama

### **B∆∞·ªõc 1: Download & Install Ollama**

1. Truy c·∫≠p: https://ollama.ai/download
2. T·∫£i b·∫£n cho Windows
3. C√†i ƒë·∫∑t (nh∆∞ c√†i ph·∫ßn m·ªÅm b√¨nh th∆∞·ªùng)
4. Ollama s·∫Ω t·ª± ƒë·ªông ch·∫°y ·ªü background

### **B∆∞·ªõc 2: Pull M√¥ H√¨nh AI**

M·ªü **Command Prompt** ho·∫∑c **PowerShell** v√† ch·∫°y:

```bash
# Pull m√¥ h√¨nh chat (ch·ªçn 1 trong c√°c m√¥ h√¨nh sau)
ollama pull llama3.2        # Llama 3.2 (4.3GB) - Khuy·∫øn ngh·ªã
ollama pull mistral         # Mistral (4.1GB) - Nhanh
ollama pull gemma2          # Gemma 2 (5.4GB) - T·ªët cho ti·∫øng Vi·ªát

# Pull m√¥ h√¨nh embedding (cho vector search)
ollama pull nomic-embed-text  # 274MB - D√πng cho t√¨m ki·∫øm
```

**L∆∞u √Ω**: L·∫ßn ƒë·∫ßu pull s·∫Ω m·∫•t 5-10 ph√∫t t√πy t·ªëc ƒë·ªô m·∫°ng.

### **B∆∞·ªõc 3: Ki·ªÉm Tra Ollama ƒêang Ch·∫°y**

```bash
ollama list  # Xem c√°c m√¥ h√¨nh ƒë√£ c√†i
```

K·∫øt qu·∫£:
```
NAME              ID              SIZE      MODIFIED
llama3.2:latest   f5f50259e1bb    4.3 GB    2 minutes ago
nomic-embed-text  0a109f422b47    274 MB    1 minute ago
```

---

## ‚öôÔ∏è C·∫•u H√¨nh ƒê√£ Thay ƒê·ªïi

### **1. pom.xml**
```xml
<!-- ‚ùå ƒê√£ x√≥a -->
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-vertex-ai-gemini-spring-boot-starter</artifactId>
</dependency>

<!-- ‚úÖ Thay b·∫±ng -->
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-ollama-spring-boot-starter</artifactId>
</dependency>
```

### **2. application.yml**
```yaml
spring:
  profiles:
    active: dev,ai-enabled  # ‚úÖ AI ƒë∆∞·ª£c k√≠ch ho·∫°t
  ai:
    ollama:
      base-url: http://localhost:11434  # Ollama server
      chat:
        options:
          model: llama3.2  # M√¥ h√¨nh chat
          temperature: 0.7
      embedding:
        options:
          model: nomic-embed-text  # M√¥ h√¨nh embedding
```

### **3. X√≥a File Google Cloud Credentials**

File `gen-lang-client-0404640351-*.json` **kh√¥ng c·∫ßn n·ªØa**, c√≥ th·ªÉ x√≥a!

---

## üéØ S·ª≠ D·ª•ng AI API

### **1. Chat v·ªõi AI**

**POST** `http://localhost:5181/api/ai/chat`

Request:
```json
{
  "prompt": "L√†m th·∫ø n√†o ƒë·ªÉ ƒë·∫∑t v√© xe?"
}
```

Response:
```json
{
  "answer": "ƒê·ªÉ ƒë·∫∑t v√© xe, b·∫°n c·∫ßn th·ª±c hi·ªán c√°c b∆∞·ªõc sau:\n1. Ch·ªçn tuy·∫øn xe b·∫°n mu·ªën ƒëi\n2. Ch·ªçn ng√†y gi·ªù xuÔøΩÔøΩÔøΩt ph√°t\n3. Ch·ªçn ch·ªó ng·ªìi\n4. Thanh to√°n\n..."
}
```

### **2. Th√™m Knowledge v√†o Database**

**POST** `http://localhost:5181/api/ai/add`

Request:
```json
{
  "title": "Quy tr√¨nh ƒë·∫∑t v√©",
  "content": "B∆∞·ªõc 1: Ch·ªçn tuy·∫øn xe. B∆∞·ªõc 2: Ch·ªçn gh·∫ø. B∆∞·ªõc 3: Thanh to√°n b·∫±ng VNPay ho·∫∑c Momo."
}
```

Response:
```json
{
  "id": 1,
  "title": "Quy tr√¨nh ƒë·∫∑t v√©",
  "content": "B∆∞·ªõc 1: Ch·ªçn tuy·∫øn xe...",
  "embedding": [0.123, 0.456, ...],
  "createdAt": "2025-10-22T23:00:00"
}
```

### **3. AI S·∫Ω Tr·∫£ L·ªùi D·ª±a Tr√™n Database**

C√°ch ho·∫°t ƒë·ªông:
1. User h·ªèi: "L√†m sao ƒë·ªÉ thanh to√°n?"
2. System t√¨m ki·∫øm trong database c√°c th√¥ng tin li√™n quan (d√πng vector search)
3. AI ƒë·ªçc th√¥ng tin ƒë√≥ v√† tr·∫£ l·ªùi c√¢u h·ªèi

**V√≠ d·ª•**:
```bash
# Th√™m knowledge
curl -X POST http://localhost:5181/api/ai/add \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Thanh to√°n",
    "content": "H·ªá th·ªëng h·ªó tr·ª£ thanh to√°n qua VNPay, Momo v√† chuy·ªÉn kho·∫£n ng√¢n h√†ng"
  }'

# H·ªèi AI
curl -X POST http://localhost:5181/api/ai/chat \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "T√¥i c√≥ th·ªÉ thanh to√°n b·∫±ng c√°ch n√†o?"
  }'

# AI s·∫Ω tr·∫£ l·ªùi:
# "B·∫°n c√≥ th·ªÉ thanh to√°n qua VNPay, Momo ho·∫∑c chuy·ªÉn kho·∫£n ng√¢n h√†ng."
```

---

## üîß Troubleshooting

### **L·ªói: "Connection refused" ho·∫∑c "Ollama not found"**

**Nguy√™n nh√¢n**: Ollama ch∆∞a ch·∫°y ho·∫∑c ch∆∞a c√†i ƒë·∫∑t

**Gi·∫£i ph√°p**:
```bash
# Ki·ªÉm tra Ollama c√≥ ch·∫°y kh√¥ng
curl http://localhost:11434/api/tags

# N·∫øu l·ªói, kh·ªüi ƒë·ªông Ollama
ollama serve
```

### **L·ªói: "Model not found"**

**Nguy√™n nh√¢n**: Ch∆∞a pull m√¥ h√¨nh

**Gi·∫£i ph√°p**:
```bash
ollama pull llama3.2
ollama pull nomic-embed-text
```

### **L·ªói: "ChatClient bean not found"**

**Nguy√™n nh√¢n**: Profile `ai-enabled` ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t

**Gi·∫£i ph√°p**: Ki·ªÉm tra `application.yml`:
```yaml
spring:
  profiles:
    active: dev,ai-enabled  # ‚Üê Ph·∫£i c√≥ 'ai-enabled'
```

---

## üÜö So S√°nh: Vertex AI vs Ollama

| Ti√™u ch√≠ | Vertex AI (Google) | Ollama (Local) |
|----------|-------------------|----------------|
| **Chi ph√≠** | $$$ T√≠nh ph√≠ theo request | ‚úÖ Mi·ªÖn ph√≠ 100% |
| **T·ªëc ƒë·ªô** | Nhanh (cloud) | T√πy m√°y t√≠nh |
| **C√†i ƒë·∫∑t** | Ph·ª©c t·∫°p (c·∫ßn Google Cloud) | ‚úÖ ƒê∆°n gi·∫£n |
| **Privacy** | D·ªØ li·ªáu g·ª≠i l√™n cloud | ‚úÖ D·ªØ li·ªáu ·ªü local |
| **Internet** | C·∫ßn internet | ‚úÖ Kh√¥ng c·∫ßn (sau khi pull) |
| **M√¥ h√¨nh** | Gemini | Llama, Mistral, Gemma |

---

## üìä C√°c M√¥ H√¨nh AI Khuy·∫øn Ngh·ªã

### **Chat Models**

| M√¥ h√¨nh | K√≠ch th∆∞·ªõc | ∆Øu ƒëi·ªÉm |
|---------|-----------|---------|
| `llama3.2` | 4.3 GB | C√¢n b·∫±ng t·ªët, khuy·∫øn ngh·ªã |
| `mistral` | 4.1 GB | Nhanh, code t·ªët |
| `gemma2` | 5.4 GB | T·ªët cho ti·∫øng Vi·ªát |
| `qwen2.5` | 4.7 GB | T·ªët cho ch√¢u √Å |

### **Embedding Models**

| M√¥ h√¨nh | K√≠ch th∆∞·ªõc | ∆Øu ƒëi·ªÉm |
|---------|-----------|---------|
| `nomic-embed-text` | 274 MB | Nhanh, ch·∫•t l∆∞·ª£ng t·ªët |
| `all-minilm` | 45 MB | R·∫•t nh·∫π, nhanh |

### **ƒê·ªïi M√¥ H√¨nh**

Trong `application.yml`:
```yaml
spring:
  ai:
    ollama:
      chat:
        options:
          model: mistral  # ‚Üê ƒê·ªïi th√†nh mistral
```

Sau ƒë√≥ pull m√¥ h√¨nh:
```bash
ollama pull mistral
```

---

## ‚ú® T√≠nh NƒÉng

‚úÖ **Chat AI mi·ªÖn ph√≠ 100%**  
‚úÖ **Vector search** - T√¨m ki·∫øm th√¥ng tin trong database  
‚úÖ **RAG (Retrieval-Augmented Generation)** - AI tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu th·ª±c  
‚úÖ **Ch·∫°y offline** - Kh√¥ng c·∫ßn internet (sau khi pull model)  
‚úÖ **Privacy** - D·ªØ li·ªáu kh√¥ng r·ªùi kh·ªèi m√°y b·∫°n  

---

## üöÄ B·∫Øt ƒê·∫ßu Ngay

1. **C√†i Ollama**: https://ollama.ai/download
2. **Pull m√¥ h√¨nh**:
   ```bash
   ollama pull llama3.2
   ollama pull nomic-embed-text
   ```
3. **Kh·ªüi ƒë·ªông ·ª©ng d·ª•ng**: `mvn spring-boot:run`
4. **Test API**: http://localhost:5181/swagger-ui.html

---

## üìû H·ªó Tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. Ki·ªÉm tra Ollama ƒëang ch·∫°y: `ollama list`
2. Ki·ªÉm tra log ·ª©ng d·ª•ng
3. Ki·ªÉm tra profile `ai-enabled` ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t

**Ollama Documentation**: https://github.com/ollama/ollama

